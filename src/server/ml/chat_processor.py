import os
import requests
import google.generativeai as genai
from typing import Dict, Any, List
from dotenv import load_dotenv
import asyncio  # Add this import for asyncio.sleep

load_dotenv()

class ChatProcessor:
    def __init__(self):
        # ES config
        self.es_url = "http://localhost:9201/knowledge/_search"
        
        # Gemini config
        api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise RuntimeError("Missing GEMINI_API_KEY/GOOGLE_API_KEY in environment")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel("gemini-2.0-flash-exp")
        
        # Translation prompt (tá»« diagnoseSystem.py)
        self.translate_prompt = """Báº¡n lÃ  chuyÃªn gia y khoa song ngá»¯. 
Nhiá»‡m vá»¥: dá»‹ch cÃ¢u há»i y khoa tiáº¿ng Viá»‡t dÆ°á»›i Ä‘Ã¢y sang tiáº¿ng Anh NGáº®N Gá»ŒN, Ä‘Ãºng thuáº­t ngá»¯.
CHá»ˆ tráº£ ra cÃ¢u tiáº¿ng Anh, khÃ´ng thÃªm gÃ¬ khÃ¡c.
CÃ¢u há»i:
"""
        
        # System prompt for medical chatbot
        self.system_prompt = """Báº¡n lÃ  trá»£ lÃ½ y khoa AI chuyÃªn nghiá»‡p vá»›i cÃ¡c nguyÃªn táº¯c sau:

ðŸ” **PHÃ‚N TÃCH TRIá»†U CHá»¨NG:**
- Äáº·t cÃ¢u há»i chi tiáº¿t Ä‘á»ƒ hiá»ƒu rÃµ triá»‡u chá»©ng
- Há»i vá» thá»i gian xuáº¥t hiá»‡n, má»©c Ä‘á»™ nghiÃªm trá»ng, yáº¿u tá»‘ kÃ­ch thÃ­ch
- Thu tháº­p thÃ´ng tin vá» tiá»n sá»­ bá»‡nh, thuá»‘c Ä‘ang dÃ¹ng

ðŸ’¡ **TÆ¯ Váº¤N Y KHOA:**
- ÄÆ°a ra giáº£i thÃ­ch dá»… hiá»ƒu vá» cÃ¡c tÃ¬nh tráº¡ng cÃ³ thá»ƒ xáº£y ra
- Äá» xuáº¥t cÃ¡c biá»‡n phÃ¡p chÄƒm sÃ³c ban Ä‘áº§u an toÃ n
- PhÃ¢n loáº¡i má»©c Ä‘á»™ cáº¥p thiáº¿t: tá»± chÄƒm sÃ³c / khÃ¡m bÃ¡c sÄ© / cáº¥p cá»©u

âš ï¸ **AN TOÃ€N & GIá»šI Háº N:**
- LUÃ”N nháº¥n máº¡nh: "ThÃ´ng tin chá»‰ mang tÃ­nh tham kháº£o, khÃ´ng thay tháº¿ bÃ¡c sÄ©"
- Khuyáº¿n nghá»‹ gáº·p bÃ¡c sÄ© náº¿u triá»‡u chá»©ng nghiÃªm trá»ng hoáº·c kÃ©o dÃ i
- KHÃ”NG cháº©n Ä‘oÃ¡n chÃ­nh thá»©c hay kÃª toa thuá»‘c

ðŸ“ **PHONG CÃCH GIAO TIáº¾P:**
- ThÃ¢n thiá»‡n, dá»… hiá»ƒu, khÃ´ng gÃ¢y lo láº¯ng
- Sá»­ dá»¥ng bullet points cho thÃ´ng tin rÃµ rÃ ng
- Há»i thÃªm thÃ´ng tin khi cáº§n thiáº¿t

HÃ£y phÃ¢n tÃ­ch cuá»™c há»™i thoáº¡i vÃ  Ä‘Æ°a ra pháº£n há»“i phÃ¹ há»£p."""

    async def process_chat_message(self, user_message: str, chat_history: List[str], session_id: str) -> Dict[str, Any]:
        """Process chat message with context from previous messages"""
        
        # Build conversation context
        conversation_context = self._build_conversation_context(chat_history, user_message)
        
        # âœ… FIX: Translate Vietnamese to English for ES search
        query_en = await self._translate_vi_to_en(user_message, chat_history)
        print(f"Translated query: '{query_en}'")
        
        # Search medical knowledge if translation successful
        medical_context = ""
        snippets = []
        if query_en and query_en.strip():
            try:
                snippets, _ = self._search_elasticsearch(query_en, topk=5)
                medical_context = "\n".join(snippets[:3])
                print(f"Found {len(snippets)} medical snippets")
            except Exception as e:
                print(f"ES search failed: {str(e)}")
        
        # Generate contextual response
        ai_response = await self._generate_chat_response(
            conversation_context, 
            user_message, 
            medical_context,
            snippets,
            query_en
        )
        
        # Analyze conversation for diagnosis context
        diagnosis_context = await self._analyze_conversation_context(chat_history + [f"user: {user_message}"])
        
        return {
            "response": ai_response,
            "diagnosis_context": diagnosis_context,
            "medical_snippets": snippets[:2] if snippets else [],
            "symptoms_detected": query_en
        }

    def _build_conversation_context(self, chat_history: List[str], current_message: str) -> str:
        """Build conversation context from chat history"""
        if not chat_history:
            return f"NgÆ°á»i dÃ¹ng: {current_message}"
        
        # Take last 10 messages for context
        recent_history = chat_history[-10:] if len(chat_history) > 10 else chat_history
        
        context = "Lá»ŠCH Sá»¬ Há»˜I THOáº I:\n"
        for message in recent_history:
            if message.startswith("user:"):
                context += f"NgÆ°á»i dÃ¹ng: {message[5:]}\n"
            elif message.startswith("assistant:"):
                context += f"Trá»£ lÃ½: {message[10:]}\n"
        
        context += f"\nTIN NHáº®N HIá»†N Táº I:\nNgÆ°á»i dÃ¹ng: {current_message}"
        return context

    async def _translate_vi_to_en(self, message: str, chat_history: List[str]) -> str:
        """âœ… FIX: Translate Vietnamese medical terms to English (theo diagnoseSystem.py)"""
        try:
            # ThÃªm retry logic
            for attempt in range(3):  # Thá»­ tá»‘i Ä‘a 3 láº§n
                try:
                    # Sá»­ dá»¥ng context nhÆ° cÅ©
                    recent_messages = chat_history[-3:] if len(chat_history) > 3 else chat_history
                    context_text = " ".join(recent_messages) + " " + message
                    
                    prompt = self.translate_prompt + context_text
                    
                    response = self.model.generate_content(prompt)
                    query_en = response.text.strip()
                    
                    print(f"Translation successful: '{message}' â†’ '{query_en}'")
                    return query_en
                
                except Exception as e:
                    # Kiá»ƒm tra xem cÃ³ pháº£i lá»—i rate limit khÃ´ng
                    if "ResourceExhausted" in str(e) or "429" in str(e):
                        print(f"API rate limited (attempt {attempt+1}/3). Waiting...")
                        # TÄƒng dáº§n thá»i gian chá» giá»¯a cÃ¡c láº§n thá»­
                        await asyncio.sleep(2 * (attempt + 1))
                    else:
                        # Náº¿u lÃ  lá»—i khÃ¡c, nÃ©m láº¡i exception
                        raise
            
            # Náº¿u thá»­ 3 láº§n Ä‘á»u tháº¥t báº¡i vÃ¬ rate limit
            print("Rate limit persists. Returning empty translation.")
            return ""
            
        except Exception as e:
            # Sá»­ dá»¥ng ASCII-safe log
            print(f"Translation failed: {str(e)}")
            return ""

    def _search_elasticsearch(self, query: str, topk: int = 5):
        """âœ… Search medical knowledge in Elasticsearch (theo diagnoseSystem.py)"""
        try:
            # Same payload as diagnoseSystem.py
            payload = {
                "query": {"match": {"body": query}}, 
                "size": topk
            }
            
            response = requests.post(self.es_url, json=payload, timeout=30)
            response.raise_for_status()
            
            hits = response.json().get("hits", {}).get("hits", [])
            snippets = [hit["_source"]["body"] for hit in hits if "body" in hit["_source"]]
            
            print(f"ES returned {len(snippets)} results for query: {query}")
            return snippets, len(hits)

        except Exception as e:
            print(f"Elasticsearch error: {str(e)}")
            return [], 0

    async def _generate_chat_response(self, conversation_context: str, user_message: str, medical_context: str, snippets: List[str] = None, query_en: str = "") -> str:
        """Generate chat response with medical context"""
        try:
            # ThÃªm retry logic cho API calls
            for attempt in range(3):
                try:
                    prompt = f"""{self.system_prompt}

{conversation_context}

"""
                
                    # âœ… FIX: Add medical context with citation requirement (theo diagnoseSystem.py)
                    if medical_context.strip() and snippets:
                        prompt += f"""
THÃ”NG TIN Y KHOA LIÃŠN QUAN (tá»« tÃ¬m kiáº¿m: "{query_en}"):
{medical_context}

**YÃŠU Cáº¦U Báº®T BUá»˜C:** 
- Sá»­ dá»¥ng thÃ´ng tin y khoa trÃªn Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c
- PHáº¢I bao gá»“m pháº§n "**Nguá»“n (trÃ­ch sÃ¡ch):**" á»Ÿ cuá»‘i
- TrÃ­ch dáº«n 1-2 cÃ¢u tiÃªu biá»ƒu tá»« nguá»“n (giá»¯ nguyÃªn tiáº¿ng Anh trong dáº¥u ngoáº·c kÃ©p)
- Format chÃ­nh xÃ¡c: **Nguá»“n (trÃ­ch sÃ¡ch):** "exact English quote from medical source"

"""

                    prompt += "\nTrá»£ lÃ½ AI:"
                    
                    response = self.model.generate_content(prompt)
                    return response.text.strip()
                    
                except Exception as e:
                    if "ResourceExhausted" in str(e) or "429" in str(e):
                        print(f"API rate limited in response generation (attempt {attempt+1}/3). Waiting...")
                        await asyncio.sleep(2 * (attempt + 1))
                    else:
                        raise
                        
            # Fallback message if all attempts fail
            return "Xin lá»—i, tÃ´i Ä‘ang gáº·p sá»± cá»‘ káº¿t ná»‘i. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt."
            
        except Exception as e:
            print(f"Response generation failed: {str(e)}")
            return "ÄÃ£ xáº£y ra lá»—i khi xá»­ lÃ½ tin nháº¯n cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i."

    async def _analyze_conversation_context(self, full_history: List[str]) -> Dict[str, Any]:
        """Analyze conversation to extract diagnosis context"""
        try:
            return {
                "symptoms_mentioned": [],
                "duration": "unknown", 
                "severity": "unknown",
                "key_concerns": [],
                "recommendation_level": "see_doctor"
            }
        except Exception as e:
            return {"error": str(e)}